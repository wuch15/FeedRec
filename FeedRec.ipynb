{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers \n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "UserLogName = 'UserLog.tsv'\n",
    "NewsContentName = 'News.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_news(path,filenames):\n",
    "    news={}\n",
    "    category=[]\n",
    "    news_index={}\n",
    "    index=1\n",
    "    word_dict={}\n",
    "    word_index=1\n",
    "    with open(os.path.join(path,filenames), encoding='utf-8') as f:\n",
    "        lines=f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        splited = line.strip('\\n').split('\\t')\n",
    "        doc_id,vert,title,_= splited[0:4]\n",
    "        news_index[doc_id]=index\n",
    "        index+=1\n",
    "        category.append(vert)\n",
    "        title = title.lower()\n",
    "        title=title.split()\n",
    "        news[doc_id]=[vert,title]\n",
    "        for word in title:\n",
    "            word = word.lower()\n",
    "            if not(word in word_dict):\n",
    "                word_dict[word]=word_index\n",
    "                word_index+=1\n",
    "    category=list(set(category))\n",
    "    category_dict={}\n",
    "    index=0\n",
    "    for c in category:\n",
    "        category_dict[c]=index\n",
    "        index+=1\n",
    "\n",
    "    return news,news_index,category_dict,word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['442A918544141879438307453F128295', 'tp_animals,hp1_science,tp_science,hp1_environment,tp_nature,tp_zoology,tp_evolutionary_biology,tp_animal_behavior,sg_science,tp8_giraffes,tp8_lightning,tp8_animals,tp8_weather,tp8_evolutionary_biology,tp8_entomology,tp8_zoology,tp8_species,tp8_nature,tp8_wild_life,sg8_environment,kw_lightning,expsg_science,hpsg_science,hpsg_environment,fasttp_animals,fasttp_giraffes,fasttp_weather,fasttp_zoology,kp_fuzzy_lightning_rods,kp_giraffes,kp_south_africa,kp_luca_galuzzi,kp_george_dvorsky,kp_basically_fuzzy_lightning_rods,kp_research', 'Giraffes Are Basically Fuzzy Lightning Rods, New Research Suggests', 'Earlier this year, conservationists in South Africa discovered two adult giraffes struck down by lightning, signa ling a potentially underrated risk for this majestic species. Lightning kills around 27 people in the United States each year, but the quantity and frequency of animal deaths as a result of these electrical outbursts is a complete mystery.']\n",
      "['45BD86F51E573F4DC4C3E74386EAC311', 'hp1_politics,tp_politics,tp_terrorism,sg_education,sg_law,sg_politics,sg_war_terrorism,tp8_politics,tp8_medicine_and_healthcare,tp8_health,tp8_terrorism,tp8_weather,tp8_medicare_united_states,tp8_u_s_elections,sg8_health,expsg_politics,hpsg_politics,fasttp_politics_of_the_united_states_of_america,kp_virus_cases,kp_us_heartland,kp_virus_cases_rise,kp_ralph_northam,kp_pam_northam,kp_richmond', 'Virus cases rise in US heartland, home to anti-mask feelings', 'It began with devastation in the New York City area, followed by a summertime crisis in the Sun Belt. Now the coronavirus is striking cities with much smaller populations in the heartland, often in conservative corners of America where anti-mask sentiment runs high. The spread has created new problems at hospitals, schools and colleges in the Midwest, as well as in parts of the West.']\n",
      "['4C9267019836E36ED5C8B7DB378A19A3', 'hp1_sports,tp_sports,tp_hockey,tp_czech_republic,tp_wta_tour,sg_sports,tp8_sports,tp8_wta_tour,tp8_tennis,tp8_john_o_brien,tp8_formula_1,tp8_french_open,sg8_sports,local_seattle_wa,local_feeds,local_sports,expsg_sports,hpsg_sports,cluster_tennis_V1,fasttp_tennis,fasttp_tennis_players,fasttp_sports,fasttp_cricket_sport,fasttp_paris,kp_jelena_ostapenko,kp_champ_ostapenko,kp_karolina_pliskova,kp_alessandra_tarantino,kp_latvia,kp_former_champ,kp_3rd_round_the_associated_press,kp_the_associated_press', 'The Latest: Former champ Ostapenko reaches 3rd round', \"Latvia's Jelena Ostapenko clenches her fist after scoring a point against Karolina Pliskova of the Czech Republic in the second round match of the French Open tennis tournament at the Roland Garros stadium in Paris, France, Thursday, Oct. 1, 2020. Former champion Jelena Ostapenko reached the third round by beating second-seeded Karolina Pliskova 6-4, 6-2.\"]\n",
      "['1DE099CBF649F7463A57366A4DAF6B21', 'hp1_politics,tp_politics,tp_terrorism,tp_democratic_party_u_s,hp1_law,tp_crime,sg_law,sg_politics,tp8_u_s_congress,tp8_politics,tp8_republican_party_u_s,tp8_2011_protests,tp8_democratic_party_u_s,tp8_u_s_elections,sg8_politics,kw_teen--accused,kw_city--star,expsg_politics,hpsg_politics,fasttp_guns_and_firearms,fasttp_politics_of_the_united_states_of_america,fasttp_democratic_party_us_politics,fasttp_liberalism_politics,kp_kentucky_congressman,kp_kansas_city_star,kp_teen_accused,kp_republican,kp_thomas_massie,kp_congressman_defends,kp_teen_accused_in_protest,kp_protest_deaths', 'Kentucky congressman defends teen accused in protest deaths | The Kansas City Star', 'A Kentucky congressman said a teenager charged with fatally shooting two people with a semi-automatic rifle during the unrest in Wisconsin showed “incredible restraint\" and acted in self-defense. Rep. Thomas Massie also told a radio interviewer on Thursday that if he were on the jury, he would vote to acquit the teenager if the evidence was based on video he had seen of the melee.']\n",
      "['00793C24715BEF1F372DFB5D347FDAAA', 'tp_california_state,tp_us_west,tp_southern_california,tp_orange_county_ca,tp_los_angeles_ca,tp_northern_california,tp_laws_in_california,tp8_politics,tp8_healthcare_it,tp8_life_sciences,fasttp_california_state,fasttp_health,fasttp_fitness,kp_california_fitness_centers,kp_california_fitness_alliance,kp_los_angeles,kp_virus_closures,kp_gavin_newsom,kp_gulf_coast,kp_hurricane_sally', 'California fitness centers sue state over virus closures', \"LOS ANGELES (AP) — California fitness centers have filed a lawsuit alleging Gov. Gavin Newsom's measures aimed at curbing the spread of the coronavirus unfairly target the industry and are demanding they be allowed to reopen. The California Fitness Alliance, which represents nearly 300 businesses, filed the suit in Los Angeles County Superior Court, Scott Street, a lawyer for the group, said Tuesday.\"]\n",
      "['0C09DE57F3BD794CC43FDF02DEB58EE8', 'tp_china,tp_world_americas,hp1_technology,tp_iphone_applications,tp_medicare_united_states,tp_north_america,tp8_wechat_company,tp8_tencent_company,tp8_internet_in_china,tp8_internet_companies_in_china,sg8_business,kw_trump--ban,kw_wechat,kw_iphone,kw_trump,expsg_technology,hpsg_technology,fasttp_mobile_applications,fasttp_wechat,fasttp_china,fasttp_android_applications,kp_trump_ban,kp_wechat_iphone_downloads,kp_iphone_downloads_surge,kp_donald_trump,kp_wechat_iphone_downloads_surge', 'WeChat iPhone Downloads Surge in the U.S. Ahead of Trump Ban', '(Bloomberg) -- IPhone users in the U.S. are rushing to install messaging app WeChat days before President Donald Trump is set to ban downloads in the country. WeChat downloads surged to make it the 100th most-downloaded app in the U.S. on Friday, according to mobile analytics firm SensorTower. It has typically ranked between 1,000th and 1,500th this year.']\n",
      "['007C6023ACE9A5C4FA64BB4ED55858F2', 'tp_chicago,tp_pittsburgh_pa,hp1_politics,tp_politics,sg_education,sg_politics,tp8_politics,tp8_government,tp8_democratic_party_u_s,sg8_politics,expsg_politics,hpsg_politics,fasttp_police_and_law_enforcement,kp_cares_act,kp_jackson_township,kp_cares_act_funds,kp_jackson,kp_act_funds,kp_economic_security_act,kp_jackson_twp,kp_twp', 'Jackson spreads CARES Act funds between departments', 'CARES Act money is helping Jackson Township cover coronavirus related expenses on several departments. Trustees approved dividing more than $700,000 from the Coronavirus Aid, Relief and Economic Security Act between different departments during Tuesday’s meeting. The largest amount will be used to install fencing around the new amphitheater in North Park.']\n",
      "['00000B90B05102AC5AF35294A143F1F4', 'hp1_auto,tp_electric_vehicles,tp_automotive_industry,tp_cars_and_automobiles,hp1_business,tp_public_transportation,tp_transport,tp_aerospace_and_aeronautical_engineering,sg_cars_and_automobile,tp8_public_transportation,tp8_electric_vehicles,tp8_automotive_industry,tp8_autonomous,tp8_vehicles,tp8_specific_car_companies,tp8_autonomous_driving,tp8_sports_cars,tp8_robotics,sg8_cars_and_automobile,kw_electric--vehicle,expsg_auto,hpsg_auto,fasttp_cars_and_automobiles,fasttp_product_design_of_physical_goods,fasttp_driving,kp_aerospace_center,kp_german_aerospace_center,kp_germany,kp_electric_vehicle,kp_modular_electric_vehicle,kp_brittany_chang', \"Germany's aerospace center has unveiled a concept modular electric vehicle that can change from a bus to a cargo van\", 'Deutsches Zentrum für Luft und Raumfahrt (DLR), the German Aerospace Center, has unveiled the U-Shift, a concept electric vehicle that uses \"capsule\" add-ons to turn the four-wheeler into different vehicles, like a bus or cargo delivery unit. A prototype version that\\'s the size of a \"large van\" was unveiled at a conference earlier this month in Baden-Württemberg, Germany.']\n",
      "['485DAF8030ADB0639AA7F8D0F3F51D38', 'tp_national_parks_of_the_united_states,tp_grizzly_bears,tp_polar_bears,tp_bears_animal,tp_bears,tp8_grizzly_bears,tp8_polar_bears,tp8_hunting,tp8_bears_animal,tp8_wild_life,tp8_nature,tp8_the_environment,sg8_environment,kw_alaska,fasttp_animals,fasttp_bears_animal,fasttp_hunting,kp_grizzly_bear_attack,kp_phil_helsel,kp_officials,kp_alaska,kp_hunter_killed,kp_austin_pfeiffer,kp_ohio_man', \"Officials: Hunter killed in 'surprise' grizzly bear attack in Alaska identified\", 'An Ohio man who was killed by a grizzly bear in an Alaska national park was alone at the time because his hunting partner had gone back to camp to take meat from a moose they had killed, a park official said. Austin Pfeiffer, 22, was killed Sunday by a grizzly bear in Wrangell-St. Elias National Park and Preserve in what the park called a \"surprise attack.\"']\n",
      "['07D36EB3EE345261B099359BDF72DD65', 'hp1_economics,tp_economics,tp_world_economic_forum,hp1_politics,tp_politics,tp_developing_countries,tp_middle_east,tp_labor_economics,tp_world_bank,sg_economics,tp8_developing_countries,tp8_world_economic_forum,tp8_economics,tp8_economic_development,tp8_government,tp8_world_bank,tp8_international_development,tp8_social_safety_net,tp8_brain_drain,tp8_international_economics,sg8_economics,expsg_economics,hpsg_economics,cluster_economic_growth_V1,cluster_international_trade_V1,fasttp_economics,fasttp_inflation_economics,fasttp_international_economics,fasttp_the_middle_east,kp_arab_countries,kp_covid,kp_arab_region,kp_g20_group,kp_ilo,kp_working_hours,kp_international_labour_organisation,kp_imf', 'Arab countries lost 90.5% of working hours in 2Q 2020 due to COVID-19: ILO Director', 'Working hours shrank globally by 70.4 percent in the second quarter of 2020, while 90.5 percent of working hours were lost in the Arab region in the same quarter due to the ongoing COVID-19 crisis, Director-General of the International Labour Organisation (ILO) Guy Ryder revealed. Ryder made the comments during a high-level panel held on Wednesday organised by the G20 Group and the International Monetary Fund (IMF) on enhancing access to opportunities in Arab countries.']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(root_path,NewsContentName), encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines[:10]:\n",
    "        print(line.strip('\\n').split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time news,news_index,category_dict,word_dict = read_news(root_path,NewsContentName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE = 30\n",
    "def get_doc_input(news,news_index,category,word_dict):\n",
    "    news_num=len(news)+1\n",
    "    news_title=np.zeros((news_num,MAX_SENTENCE),dtype='int32')\n",
    "    news_vert=np.zeros((news_num,),dtype='int32')\n",
    "    for key in tqdm(news):    \n",
    "        vert,title=news[key]\n",
    "        doc_index=news_index[key]\n",
    "        news_vert[doc_index]=category[vert]\n",
    "        for word_id in range(min(MAX_SENTENCE,len(title))):\n",
    "            news_title[doc_index,word_id]=word_dict[title[word_id].lower()]\n",
    "        \n",
    "    return news_title,news_vert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title,news_vert=get_doc_input(news,news_index,category_dict,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'FFFFF', '1601141277', 'scroll', 'Opal_VideoCandidate_0916&Android', '9ACF01F02C244E629E16D384D9481F0B', '', '', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'A7362C72BCA7376007AA7517BBD56226', '1601141277', 'seen', 'Opal_VideoCandidate_0916&Android', '9ACF01F02C244E629E16D384D9481F0B', 'NewsDigest', '0', '44.449', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'E09E1EB34E63D00848F400D83242E0D6', '1601141277', 'seen', 'Opal_VideoCandidate_0916&Android', '9ACF01F02C244E629E16D384D9481F0B', 'NewsDigest', '1', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'FFFFF', '1601209489', 'scroll', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', '', '', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '95D02CD332A88D200C752D6915017227', '1601209489', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'MiniCard', '4', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'B509CAD0C0CE5DBBDD07A4F55AA695C0', '1601209489', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'NewsDigest', '2', '8.256', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '0748E8FC1E6CE52075EC41C8BC51D1E8', '1601209489', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'NewsDigest', '0', '4.854', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '3CBCA22692C6394C6CC4BD2D7091BBB2', '1601209489', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '3', '3.651', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '3DFEACB8663A3ECB62136102BF2D2E5A', '1601209489', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'NewsDigest', '1', '8.35', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '3BD5E7348AA675341B489CC0C01DE75F', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '16', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '95D02CD332A88D200C752D6915017227', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'MiniCard', '4', '2.913', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'EBB5B36F2C427E35463CC2656EB2D986', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '18', '1.672', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'B086558E942B552C019971E273A19AB8', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'VideoCard', '19', '1.952', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '0FB14D067ECD0CC7D5E75AFBC227EF72', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '23', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '1D79DCE46EBA8E00063D86CA26520AAE', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'MiniCard', '12', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '0748E8FC1E6CE52075EC41C8BC51D1E8', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'NewsDigest', '0', '0', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', 'F18BF9E8FACDD3A5B03C56679400FA5C', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '7', '2.736', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '3BD5E7348AA675341B489CC0C01DE75F', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '16', '2.449', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '3CBCA22692C6394C6CC4BD2D7091BBB2', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '3', '1.965', '0']\n",
      "['0000345EFA9B41A88AEC4DFEF5EBED40', '2A5167084860E257F1FFA780538235CE', '1601209526', 'seen', 'Opal&Android', '151353D1D2E347349BD9ADA00FF0B8F5', 'Card', '14', '1.737', '0']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(root_path,UserLogName)) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:20]:\n",
    "        print(line.strip('\\n').split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logs():\n",
    "    def __init__(self,newsid,eventime,action,dt):\n",
    "        self.newsid = newsid\n",
    "        self.eventime = eventime\n",
    "        self.action = action\n",
    "        self.dt = dt\n",
    "    def __lt__(self,log):\n",
    "        return self.eventime<log.eventime\n",
    "    def __gt__(self,log):\n",
    "        return self.eventime>log.eventime\n",
    "    def __eq__(self,log):\n",
    "        return self.eventime==log.eventime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actiontypeid={'NULL': -1,\n",
    " 'scroll':-1,\n",
    " 'seen': 0,\n",
    " 'click': 1,\n",
    " 'articlestatus': 0,\n",
    " 'read': 2,\n",
    " 'play': 0,\n",
    " 'pause': 0,\n",
    " 'finish': 3,\n",
    " 'share': 4,\n",
    " 'pulltorefresh': -1,\n",
    " 'dislikeprovider': 5,\n",
    " 'dislikecard': 5,\n",
    " 'report': -1,\n",
    " 'saved': -1,\n",
    " 'fullscreen': -1,\n",
    " 'new_user': -1,\n",
    " 'unseen': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class User():\n",
    "    def __init__(self,userid):\n",
    "        self.userid = userid\n",
    "        self.logs = []\n",
    "        self.sort_flag = True\n",
    "        \n",
    "    def add_log(self,newsid,eventime,action,dt):\n",
    "        eventime = int(eventime)\n",
    "        self.logs.append(Logs(newsid,eventime,action,dt))\n",
    "        self.sort_flag = False\n",
    "    def sort_log(self,):\n",
    "        self.logs.sort()\n",
    "        self.sort_flag = True\n",
    "    \n",
    "    def positive_log(self,):\n",
    "        if not self.sort_flag:\n",
    "            self.sort_log()\n",
    "            \n",
    "        self.click_newsid = []\n",
    "        self.click_action = []\n",
    "        self.click_eventime = []\n",
    "        self.click_dt = []\n",
    "        for i in range(len(self.logs)):\n",
    "            if actiontypeid[self.logs[i].action]!=-1:\n",
    "                #if not self.logs[i].newsid in self.click_newsid:\n",
    "                self.click_newsid.append(self.logs[i].newsid)\n",
    "                self.click_eventime.append(self.logs[i].eventime)\n",
    "                self.click_action.append(self.logs[i].action)\n",
    "                self.click_dt.append(self.logs[i].dt)\n",
    "                \n",
    "        self.click_newsid = np.array(self.click_newsid)\n",
    "        self.click_eventime = np.array(self.click_eventime)\n",
    "        self.click_action = np.array(self.click_action)\n",
    "        self.click_dt = np.array(self.click_dt)\n",
    "        \n",
    "    def get_impression(self,):\n",
    "        self.impressions= []\n",
    "        self.valid_impressions = []\n",
    "        impression = []\n",
    "        pos_flag = False\n",
    "        neg_flag = False\n",
    "        for i in range(len(self.logs)):\n",
    "            log = self.logs[i]\n",
    "            if log.action == 'scroll' or log.action == 'pulltorefresh':\n",
    "                if len(impression)>0:\n",
    "                    if pos_flag and neg_flag:\n",
    "                        self.valid_impressions.append(impression)\n",
    "                    self.impressions.append(impression)\n",
    "                impression = []\n",
    "                pos_flag = False\n",
    "                neg_flag = False\n",
    "                continue\n",
    "            impression.append(i)\n",
    "            if actiontypeid[log.action] in [1,2,3,4]:\n",
    "                pos_flag = True\n",
    "            if actiontypeid[log.action] in [0,5]:\n",
    "                neg_flag = True\n",
    "                \n",
    "    def process_log_pos(self,):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users = {}\n",
    "skip = 0\n",
    "skiped_news = {}\n",
    "skiped_action={}\n",
    "dt_dict = {}\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    userid, newsid, eventime, action, _,sid, size, position, lingertime, dt = lines[i].strip('\\n').split('\\t')\n",
    "    if not userid in Users:\n",
    "        Users[userid] = User(userid)\n",
    "    if not dt in dt_dict:\n",
    "        dt_dict[dt] = len(dt_dict) + 1\n",
    "        \n",
    "    eventime = int(eventime)\n",
    "    if not newsid in news_index and newsid !='FFFFF':\n",
    "        skip += 1\n",
    "        if not newsid in skiped_news:\n",
    "            skiped_news[newsid] = True\n",
    "        skiped_action[action]=skiped_action.get(action,0)+1\n",
    "\n",
    "        continue\n",
    "    Users[userid].add_log(newsid,eventime,action,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for userid in tqdm(Users):\n",
    "    Users[userid].sort_log()\n",
    "    Users[userid].positive_log()\n",
    "    Users[userid].get_impression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "def trans2tsp(timestr):\n",
    "    return int(time.mktime(datetime.strptime(timestr, '%m/%d/%Y %I:%M:%S %p').timetuple()))\n",
    "\n",
    "anchor = trans2tsp('09/29/2020 07:00:00 AM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(click_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samples = []\n",
    "npratio=4\n",
    "for cnt,userid in tqdm(enumerate(Users)):\n",
    "    user = Users[userid]\n",
    "    if cnt>=10:\n",
    "        break\n",
    "    logs = user.logs\n",
    "    click_newsid = user.click_newsid\n",
    "    click_action = user.click_action\n",
    "    click_dt = user.click_dt\n",
    "    if len(click_newsid) < 3:\n",
    "        continue\n",
    "    \n",
    "    click_eventime = user.click_eventime\n",
    "    imps = user.valid_impressions\n",
    "\n",
    "    for imp in imps:\n",
    "        \n",
    "        imp_time = logs[imp[0]].eventime\n",
    "        if imp_time>anchor:\n",
    "            continue\n",
    "            \n",
    "        index = click_eventime<imp_time\n",
    "\n",
    "        clicks = click_newsid[index]\n",
    "        clicks = clicks.tolist()\n",
    "\n",
    "        eventime = click_eventime[index]\n",
    "        eventime = eventime.tolist()\n",
    "        actions = click_action[index]\n",
    "        actions = actions.tolist()\n",
    "        dts = click_dt[index]\n",
    "        dts = dts.tolist()\n",
    "        \n",
    "        reserveid=[]\n",
    "        for ac in range(len(clicks)):\n",
    "            if actiontypeid[actions[ac]]==0 and random.randint(0,10)!=0:    \n",
    "                continue\n",
    "            else:\n",
    "                reserveid.append(ac)\n",
    "        clicks=[clicks[y] for y in reserveid]\n",
    "        actions=[actions[y] for y in reserveid]\n",
    "        dts=[dts[y] for y in reserveid]\n",
    "        et=[eventime[y] for y in reserveid]\n",
    "        if len(et)==0:\n",
    "            interval=[]\n",
    "        else:\n",
    "            interval=  [0]+[et[_+1]-et[_] for _ in range(len(et)-1)]  \n",
    "        pos = []\n",
    "        neg = []\n",
    "        posaction = []\n",
    "        negaction = []\n",
    "        posdt = []\n",
    "        negdt = []\n",
    "        for logid in imp:\n",
    "            log = logs[logid]\n",
    "            if log.newsid in pos:\n",
    "                continue\n",
    "            if actiontypeid[log.action] in [1,2,3,4]:\n",
    "                pos.append(log.newsid)\n",
    "                posaction.append(log.action)\n",
    "                posdt.append(log.dt)\n",
    "            else:\n",
    "                neg.append(log.newsid)\n",
    "                negaction.append(log.action)\n",
    "                negdt.append(log.dt)\n",
    "        \n",
    "        if len(neg) == 0 or len(pos) == 0:\n",
    "            continue\n",
    "                    \n",
    "        #print(pos)\n",
    "        #print(neg)\n",
    "        \n",
    "        index1 = np.random.permutation(len(pos))\n",
    "        index2 = np.random.permutation(len(neg)) \n",
    "        \n",
    "        if len(neg) < npratio:\n",
    "            neg = neg * (npratio // len(neg) + 1)\n",
    "            negaction = negaction * (npratio // len(negaction) + 1)\n",
    "            negdt = negdt * (npratio // len(negdt) + 1)\n",
    "        \n",
    "        for i in range(len(pos)):\n",
    "            index2 = np.random.permutation(len(neg))[:npratio]\n",
    "            Samples.append([\n",
    "                pos[index1[i]],posaction[index1[i]],posdt[index1[i]],\n",
    "                [neg[i] for i in index2],[negaction[i] for i in index2],[negdt[i] for i in index2],\n",
    "                imp_time,clicks[-100:],actions[-100:],dts[-100:],interval[-100:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSamples = []\n",
    "\n",
    "for cnt,userid in tqdm(enumerate(Users)):\n",
    "    user = Users[userid]\n",
    "    if cnt>=10:\n",
    "        break\n",
    "    logs = user.logs\n",
    "    click_newsid = user.click_newsid\n",
    "    click_action = user.click_action\n",
    "    click_dt = user.click_dt\n",
    "    if len(click_newsid) < 3:\n",
    "        continue\n",
    "        \n",
    "    click_eventime = user.click_eventime \n",
    "    \n",
    "    imps = user.valid_impressions\n",
    "\n",
    "    for imp in imps:\n",
    "        \n",
    "        imp_time = logs[imp[0]].eventime\n",
    "        if imp_time<=anchor:\n",
    "            continue\n",
    "            \n",
    "        index = click_eventime<imp_time\n",
    "\n",
    "        clicks = click_newsid[index]\n",
    "        clicks = clicks.tolist()\n",
    "\n",
    "        eventime = click_eventime[index]\n",
    "        eventime = eventime.tolist() \n",
    "        actions = click_action[index]\n",
    "        actions = actions.tolist()\n",
    "        dts = click_dt[index]\n",
    "        dts = dts.tolist()\n",
    "        \n",
    "        reserveid=[]\n",
    "        for ac in range(len(clicks)):\n",
    "            if actiontypeid[actions[ac]]==0 and random.randint(0,10)!=0:    \n",
    "                continue\n",
    "            else:\n",
    "                reserveid.append(ac)\n",
    "        clicks=[clicks[y] for y in reserveid]\n",
    "        actions=[actions[y] for y in reserveid]\n",
    "        dts=[dts[y] for y in reserveid]\n",
    "        et=[eventime[y] for y in reserveid]\n",
    "        if len(et)==0:\n",
    "            interval=[]\n",
    "        else:\n",
    "            interval=  [0]+[et[_+1]-et[_] for _ in range(len(et)-1)]  \n",
    "        posdt = []\n",
    "        negdt = []\n",
    "        pos = []\n",
    "        neg = [] \n",
    "        posaction = []\n",
    "        negaction = []\n",
    "        posdt = []\n",
    "        negdt = []\n",
    "        for logid in imp:\n",
    "            log = logs[logid]\n",
    "            if log.newsid in pos:\n",
    "                continue\n",
    "            if actiontypeid[log.action] in [1,2,3,4]:\n",
    "                pos.append(log.newsid)\n",
    "                posaction.append(log.action)\n",
    "                posdt.append(log.dt)\n",
    "            else:\n",
    "                neg.append(log.newsid)\n",
    "                negaction.append(log.action)\n",
    "                negdt.append(log.dt)\n",
    "        \n",
    "        if len(pos) ==0 or len(neg) ==0:\n",
    "            continue\n",
    "\n",
    "        TestSamples.append([pos,posaction,posdt,neg,negaction,negdt, imp_time,clicks[-100:],actions[-100:],dts[-100:],interval[-100:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('News.tsv',encoding='utf-8') as f:\n",
    "    newsdata=f.readlines()  \n",
    "news={}\n",
    "for line in newsdata:\n",
    "    linesplit=line.strip().split('\\t')\n",
    "    news[linesplit[0]]=[word_tokenize(linesplit[2].lower())]\n",
    "    \n",
    "newsindex={'NULL':0} \n",
    "for newsid in news:\n",
    "    newsindex[newsid]=len(newsindex) \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def newsample(array,ratio):\n",
    "    if ratio >len(array):\n",
    "        return random.sample(array*(ratio//len(array)+1),ratio)\n",
    "    else:\n",
    "        return random.sample(array,ratio)\n",
    "\n",
    "idx=0\n",
    "npratio=4\n",
    "\n",
    "train_candidate=[] \n",
    "train_candidate_dt=[] \n",
    "train_candidate_interval=[] \n",
    "train_candidate_action=[]  \n",
    "train_candidate_mask=[] \n",
    "train_label=[] \n",
    "train_user_his=[]\n",
    "train_user_hisaction=[]\n",
    "train_user_hisdt=[]\n",
    "train_user_hisinterval=[]\n",
    "train_user_hismask0=[]\n",
    "train_user_hismask1=[]\n",
    "train_user_hismask2=[]\n",
    "train_user_hismask3=[]\n",
    "train_user_hismask4=[]\n",
    "train_user_hismask5=[] \n",
    "for x in tqdm(Samples):\n",
    "    \n",
    "    if x[0] not in newsindex:\n",
    "        continue\n",
    "    clickids=[newsindex.get(k,0) for k in x[7]][-100:]    \n",
    "    actionids=[actiontypeid.get(k,0) for k in x[8]][-100:] \n",
    "    clickdts=[np.round(np.log2(1+float(k))) for k in x[9]][-100:]\n",
    "    clickintervals=[np.round(np.log2(1+float(k))) for k in x[10]][-100:]\n",
    "    clickdtsraw= [float(k) for k in x[9][-100:]]\n",
    "    actionids0=[int(k==0) for k in actionids]\n",
    "    actionids1=[int(k==1) for k in actionids]\n",
    "    \n",
    "    for k in range(len(actionids)):\n",
    "        if actionids[k]==2 and clickdtsraw[k]<10:\n",
    "            actionids[k]=6\n",
    "    \n",
    "    actionids2=[int(k==3) for k in actionids]\n",
    "    actionids3=[int(k==4) for k in actionids]\n",
    "    actionids4=[int(k==5) for k in actionids]\n",
    "    actionids5=[int(k==6) for k in actionids]\n",
    "    pdoc = newsindex[x[0]]\n",
    "    paction=actiontypeid.get(x[1],0)\n",
    "    pdt = x[2]\n",
    "    ndoc = [newsindex.get(k,0) for k in x[3]]\n",
    "    naction=[actiontypeid.get(k,0) for k in x[4]]\n",
    "    ndt = x[5]\n",
    "    negd=ndoc+[pdoc]\n",
    "    nega=naction+[paction]   \n",
    "    negpdt=ndt+[pdt]    \n",
    "    for k in range(len(negpdt)):\n",
    "        if nega[k]==3:\n",
    "            nega[k]=1\n",
    "        else:\n",
    "            nega[k]=0 \n",
    "\n",
    "    negpdta=[np.round(np.log2(1+float(k))) for k in negpdt]\n",
    "    \n",
    "    candidate_label=[0]*npratio+[1]\n",
    "    candidate_order=list(range(npratio+1))\n",
    "    random.shuffle(candidate_order)\n",
    "    candidate_shuffle=[]\n",
    "    candidate_dt_shuffle=[]\n",
    "    candidate_action_shuffle=[]\n",
    "    candidate_label_shuffle=[]\n",
    "    for i in candidate_order:\n",
    "        candidate_shuffle.append(negd[i])\n",
    "        candidate_action_shuffle.append(nega[i])\n",
    "        candidate_label_shuffle.append(candidate_label[i])\n",
    "        candidate_dt_shuffle.append(negpdta[i])\n",
    "    train_candidate.append(candidate_shuffle)\n",
    "    train_candidate_mask.append(np.sum(nega))\n",
    "    train_candidate_dt.append(candidate_dt_shuffle)\n",
    "    train_label.append(candidate_label_shuffle)\n",
    "    train_user_his.append(clickids+[0]*(100-len(clickids))) \n",
    "    train_candidate_action.append(candidate_action_shuffle)\n",
    "    train_user_hisdt.append(clickdts+[0]*(100-len(actionids))) \n",
    "    train_user_hisinterval.append(clickintervals+[0]*(100-len(actionids)))  \n",
    "    print(len(clickintervals+[0]*(100-len(actionids))))\n",
    "    train_user_hisaction.append(actionids+[0]*(100-len(actionids))) \n",
    "    train_user_hismask0.append(actionids0+[0]*(100-len(actionids0))) \n",
    "    train_user_hismask1.append(actionids1+[0]*(100-len(actionids1))) \n",
    "    train_user_hismask2.append(actionids2+[0]*(100-len(actionids2))) \n",
    "    train_user_hismask3.append(actionids3+[0]*(100-len(actionids3))) \n",
    "    train_user_hismask4.append(actionids4+[0]*(100-len(actionids4))) \n",
    "    train_user_hismask5.append(actionids5+[0]*(100-len(actionids5)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidate=[]  \n",
    "test_candidate_action=[]    \n",
    "test_candidate_dt=[]\n",
    "test_label=[]\n",
    "test_user_his=[]\n",
    "test_user_hisdt=[]\n",
    "test_user_hisinterval=[]\n",
    "test_user_hisaction=[]\n",
    "test_user_hismask0=[]\n",
    "test_user_hismask1=[]\n",
    "test_user_hismask2=[]\n",
    "test_user_hismask3=[]\n",
    "test_user_hismask4=[]\n",
    "test_user_hismask5=[] \n",
    "test_index=[]\n",
    "for x in tqdm(TestSamples):\n",
    "    pdoc=[newsindex.get(k,0) for k in x[0] if k in newsindex]\n",
    "    ndoc = [newsindex.get(k,0) for k in x[3] if k in newsindex]\n",
    "    clickids=[newsindex.get(k,0) for k in x[7]][-100:]    \n",
    "    actionids=[actiontypeid.get(k,0) for k in x[8]][-100:]     \n",
    "    clickintervals=[np.round(np.log2(1+float(k))) for k in x[10]][-100:]\n",
    "    clickdts=[np.round(np.log2(1+float(k))) for k in x[9]][-100:]\n",
    "    clickdtsraw= [float(k) for k in x[9][-100:]]\n",
    "\n",
    "    for k in range(len(actionids)):\n",
    "        if actionids[k]==2 and clickdtsraw[k]<10:\n",
    "            actionids[k]=6\n",
    "\n",
    "    \n",
    "    actionids0=[int(k==0) for k in actionids]\n",
    "    actionids1=[int(k==1) for k in actionids]\n",
    "    actionids2=[int(k==3) for k in actionids]\n",
    "    actionids3=[int(k==4) for k in actionids]\n",
    "    actionids4=[int(k==5) for k in actionids]\n",
    "    actionids5=[int(k==6) for k in actionids]\n",
    "    if len(pdoc)==0 or len(ndoc)==0:\n",
    "        continue\n",
    "        \n",
    "    paction=[actiontypeid.get(k,0) for k in x[1]]\n",
    "    pdt = [float(k) for k in x[2]]\n",
    "    ndoc = [newsindex.get(k,0) for k in x[3]]\n",
    "    naction=[actiontypeid.get(k,0) for k in x[4]]\n",
    "    ndt = [float(k) for k in x[5]]\n",
    " \n",
    "\n",
    "    index=[]\n",
    "    index.append(len(test_candidate))\n",
    "    for doc in range(len(pdoc)):\n",
    "        test_candidate.append(pdoc[doc])\n",
    "        test_candidate_action.append(paction[doc])\n",
    "        test_candidate_dt.append(pdt[doc])\n",
    "        test_label.append(1)\n",
    "        test_user_hisdt.append(clickdts+[0]*(100-len(actionids))) \n",
    "        test_user_hisinterval.append(clickintervals+[0]*(100-len(actionids)))  \n",
    "        test_user_his.append(clickids+[0]*(100-len(clickids)))  \n",
    "        test_user_hisaction.append(actionids+[0]*(100-len(actionids))) \n",
    "        test_user_hismask0.append(actionids0+[0]*(100-len(actionids0))) \n",
    "        test_user_hismask1.append(actionids1+[0]*(100-len(actionids1))) \n",
    "        test_user_hismask2.append(actionids2+[0]*(100-len(actionids2))) \n",
    "        test_user_hismask3.append(actionids3+[0]*(100-len(actionids3))) \n",
    "        test_user_hismask4.append(actionids4+[0]*(100-len(actionids4))) \n",
    "        test_user_hismask5.append(actionids5+[0]*(100-len(actionids5)))  \n",
    "    for doc in range(len(ndoc)):\n",
    "        test_candidate.append(ndoc[doc])\n",
    "        test_candidate_action.append(naction[doc])\n",
    "        test_candidate_dt.append(ndt[doc])\n",
    "        test_label.append(0)\n",
    "        test_user_hisdt.append(clickdts+[0]*(100-len(actionids))) \n",
    "        test_user_hisinterval.append(clickintervals+[0]*(100-len(actionids)))  \n",
    "        test_user_his.append(clickids+[0]*(100-len(clickids))) \n",
    "        test_user_hisaction.append(actionids+[0]*(100-len(actionids))) \n",
    "        test_user_hismask0.append(actionids0+[0]*(100-len(actionids0))) \n",
    "        test_user_hismask1.append(actionids1+[0]*(100-len(actionids1))) \n",
    "        test_user_hismask2.append(actionids2+[0]*(100-len(actionids2))) \n",
    "        test_user_hismask3.append(actionids3+[0]*(100-len(actionids3))) \n",
    "        test_user_hismask4.append(actionids4+[0]*(100-len(actionids4))) \n",
    "        test_user_hismask5.append(actionids5+[0]*(100-len(actionids5)))  \n",
    "    index.append(len(test_candidate))\n",
    "    test_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict={'PADDING':[0,999999]}\n",
    "\n",
    "for newsid in news:\n",
    "    title=[]\n",
    "    for word in news[newsid][0]:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word]=[len(word_dict),1]\n",
    "        else:\n",
    "            word_dict[word][1]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict1={}\n",
    "for i in word_dict:\n",
    "    if word_dict[i][1]>=2 and i not in word_dict1:\n",
    "        word_dict1[i]=[len(word_dict1),word_dict[i][1]]\n",
    "print(len(word_dict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_title=[[0]*30]\n",
    "\n",
    "for newsid in news:\n",
    "    title=[]\n",
    "    for word in news[newsid][0]:\n",
    "        if word in word_dict1:\n",
    "            title.append(word_dict1[word][0])\n",
    "    title=title[:30]\n",
    "    news_title.append(title+[0]*(30-len(title)))\n",
    "\n",
    "news_title=np.array(news_title,dtype='int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_candidate_dt=np.array(train_candidate_dt,dtype='float32')\n",
    "train_candidate=np.array(train_candidate,dtype='int32')\n",
    "train_candidate_mask=np.array(train_candidate_mask,dtype='float32')\n",
    "train_candidate_action=np.array(train_candidate_action,dtype='int32')\n",
    "train_label=np.array(train_label,dtype='int32')\n",
    "train_user_his=np.array(train_user_his,dtype='int32')\n",
    "train_user_hisaction=np.array(train_user_hisaction,dtype='int32')\n",
    "train_user_hisinterval=np.array(train_user_hisinterval,dtype='int32')\n",
    "train_user_hisdt=np.array(train_user_hisdt,dtype='int32')\n",
    "train_user_hismask0=np.array(train_user_hismask0,dtype='int32')\n",
    "train_user_hismask1=np.array(train_user_hismask1,dtype='int32')\n",
    "train_user_hismask2=np.array(train_user_hismask2,dtype='int32')\n",
    "train_user_hismask3=np.array(train_user_hismask3,dtype='int32')\n",
    "train_user_hismask4=np.array(train_user_hismask4,dtype='int32')\n",
    "train_user_hismask5=np.array(train_user_hismask5,dtype='int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_candidate=np.array(test_candidate,dtype='int32') \n",
    "test_candidate_action=np.array(test_candidate_action,dtype='int32') \n",
    "test_candidate_dt=np.array(test_candidate_dt,dtype='float32') \n",
    "test_user_his=np.array(test_user_his,dtype='int32')\n",
    "test_label=np.array(test_label,dtype='int32')\n",
    "test_user_hisaction=np.array(test_user_hisaction,dtype='int32')\n",
    "test_user_hisinterval=np.array(test_user_hisinterval,dtype='int32')\n",
    "test_user_hisdt=np.array(test_user_hisdt,dtype='int32')\n",
    "test_user_hismask0=np.array(test_user_hismask0,dtype='int32')\n",
    "test_user_hismask1=np.array(test_user_hismask1,dtype='int32')\n",
    "test_user_hismask2=np.array(test_user_hismask2,dtype='int32')\n",
    "test_user_hismask3=np.array(test_user_hismask3,dtype='int32')\n",
    "test_user_hismask4=np.array(test_user_hismask4,dtype='int32')\n",
    "test_user_hismask5=np.array(test_user_hismask5,dtype='int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_batch_data_random(batch_size):\n",
    "    idlist = np.arange(len(train_label))\n",
    "    np.random.shuffle(idlist)\n",
    "    y=train_label\n",
    "    batches = [idlist[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[train_candidate[i]]\n",
    "            user = news_title[train_user_his[i]] \n",
    "            useraction = train_user_hisaction[i]\n",
    "            userinterval = train_user_hisinterval[i]\n",
    "            userdt = train_user_hisdt[i]\n",
    "            itemaction= train_candidate_action[i]\n",
    "            useractionmask0=train_user_hismask0[i]\n",
    "            useractionmask1=train_user_hismask1[i]\n",
    "            useractionmask2=train_user_hismask2[i]\n",
    "            useractionmask3=train_user_hismask3[i]\n",
    "            useractionmask4=train_user_hismask4[i]\n",
    "            useractionmask5=train_user_hismask5[i] \n",
    "            itemdt=np.sum(train_candidate_dt[i],axis=-1,keepdims=True)\n",
    "            yield ([item,user,useraction,userdt,userinterval,useractionmask0,useractionmask1,\n",
    "                    useractionmask2,useractionmask3,useractionmask4,useractionmask5],\n",
    "                   [y[i],itemdt,itemaction,np.zeros((batch_size,1))],[np.ones((batch_size,)),np.ones((batch_size,)),train_candidate_mask[i]+1e-8,np.ones((batch_size,))])\n",
    "\n",
    "\n",
    "def generate_batch_data(batch_size):\n",
    "    idlist = np.arange(len(test_candidate))\n",
    "    batches = [idlist[range(batch_size*i, min(len(idlist), batch_size*(i+1)))] for i in range(len(idlist)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[test_candidate[i]]\n",
    "            user=news_title[test_user_his[i]]\n",
    "            useraction = test_user_hisaction[i]\n",
    "            userinterval = test_user_hisinterval[i]\n",
    "            userdt = test_user_hisdt[i]\n",
    "            useractionmask0=test_user_hismask0[i]\n",
    "            useractionmask1=test_user_hismask1[i]\n",
    "            useractionmask2=test_user_hismask2[i]\n",
    "            useractionmask3=test_user_hismask3[i]\n",
    "            useractionmask4=test_user_hismask4[i]\n",
    "            useractionmask5=test_user_hismask5[i] \n",
    "            yield ([item,user,useraction,userdt,userinterval,useractionmask0,useractionmask1,useractionmask2,useractionmask3,useractionmask4,useractionmask5])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embdict={}\n",
    "import pickle\n",
    "with open('glove.840B.300d.txt','rb')as f:\n",
    "    while True:\n",
    "        j=f.readline()\n",
    "        if len(j)==0:\n",
    "            break\n",
    "        k = j.split()\n",
    "        word=k[0].decode()\n",
    "        if len(word) != 0:\n",
    "            tp=[float(x) for x in k[1:]]\n",
    "            if word in word_dict1:\n",
    "                embdict[word]=tp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import cholesky\n",
    "\n",
    "emb_table=[0]*len(word_dict1)\n",
    "xp=np.zeros(300,dtype='float32')\n",
    "\n",
    "cand=[]\n",
    "for i in embdict:\n",
    "    emb_table[word_dict1[i][0]]=np.array(embdict[i],dtype='float32')\n",
    "    cand.append(emb_table[word_dict1[i][0]])\n",
    "cand=np.array(cand,dtype='float32')\n",
    "\n",
    "mu=np.mean(cand, axis=0)\n",
    "Sigma=np.cov(cand.T)\n",
    "\n",
    "norm=np.random.multivariate_normal(mu, Sigma, 1)\n",
    "print(mu.shape,Sigma.shape,norm.shape)\n",
    "\n",
    "for i in range(len(emb_table)):\n",
    "    if type(emb_table[i])==int:\n",
    "        emb_table[i]=np.reshape(norm, 300)\n",
    "emb_table[0]=np.zeros(300,dtype='float32')\n",
    "emb_table=np.array(emb_table,dtype='float32')\n",
    "print(emb_table.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, nb_head, size_per_head, **kwargs):\n",
    "        self.nb_head = nb_head\n",
    "        self.size_per_head = size_per_head\n",
    "        self.output_dim = nb_head*size_per_head\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.WQ = self.add_weight(name='WQ', \n",
    "                                  shape=(input_shape[0][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WK = self.add_weight(name='WK', \n",
    "                                  shape=(input_shape[1][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WV = self.add_weight(name='WV', \n",
    "                                  shape=(input_shape[2][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def Mask(self, inputs, mask, mode='mul'):\n",
    "        if mask == None:\n",
    "            return inputs\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            if mode == 'mul':\n",
    "                mask = K.expand_dims(mask,axis=2)\n",
    "                return inputs * mask\n",
    "            if mode == 'add':\n",
    "                mask = tf.matmul(K.expand_dims(mask, axis=-1),K.expand_dims(mask, axis=1))\n",
    "                mask = K.expand_dims(mask,axis=3)\n",
    "                return inputs - (1 - mask) * 1e12\n",
    "                \n",
    "    def call(self, x):\n",
    "        if len(x) == 3:\n",
    "            Q_seq,K_seq,V_seq = x\n",
    "            mask = None\n",
    "        elif len(x) == 4:\n",
    "            Q_seq,K_seq,V_seq,mask = x\n",
    "        Q_seq = K.dot(Q_seq, self.WQ)\n",
    "        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n",
    "        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n",
    "        K_seq = K.dot(K_seq, self.WK)\n",
    "        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n",
    "        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n",
    "        V_seq = K.dot(V_seq, self.WV)\n",
    "        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n",
    "        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n",
    "        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))\n",
    "\n",
    "        A = self.Mask(A, mask, 'add')\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))    \n",
    "        A = K.softmax(A)\n",
    "        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n",
    "        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n",
    "        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n",
    "        O_seq = self.Mask(O_seq, mask, 'mul')\n",
    "        return O_seq\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH=30\n",
    "MAX_SENTS=100\n",
    "\n",
    "\n",
    "keras.backend.clear_session() \n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(word_dict1), weights=[emb_table],300,trainable=True)\n",
    " \n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "\n",
    "d_et=Dropout(0.2)(embedded_sequences)\n",
    "\n",
    "d_ct= Attention(16,16)([d_et,d_et,d_et])\n",
    "#l_att=Dense(64,activation='tanh')(l_att)\n",
    "attention = Dense(200,activation='tanh')(d_ct)\n",
    "attention = Flatten()(Dense(1)(attention))\n",
    "attention_weight = Activation('softmax')(attention)\n",
    "l_att=keras.layers.Dot((1, 1))([d_ct, attention_weight])\n",
    "\n",
    "\n",
    "sentEncodert = Model([sentence_input], l_att)\n",
    "\n",
    "\n",
    "news_input = Input((MAX_SENTS,MAX_SENT_LENGTH,), dtype='int32')\n",
    "news_encoders= TimeDistributed(sentEncodert)(news_input)\n",
    "\n",
    "newsaction_input = Input((MAX_SENTS,), dtype='int32')\n",
    "action_embedding_layer = Embedding(7, 256,trainable=True)\n",
    "action_embedded_sequences = action_embedding_layer(newsaction_input)\n",
    "\n",
    "newsdt_input = Input((MAX_SENTS,), dtype='int32')\n",
    "dt_embedding_layer = Embedding(32, 256,trainable=True)\n",
    "dt_embedded_sequences = dt_embedding_layer(newsdt_input)\n",
    "\n",
    "newsinterval_input = Input((MAX_SENTS,), dtype='int32')\n",
    "interval_embedding_layer = Embedding(32, 256,trainable=True)\n",
    "interval_embedded_sequences = interval_embedding_layer(newsinterval_input)\n",
    "\n",
    "position_embedding_layer = Embedding(100, 256,trainable=True)\n",
    "position_embedded_sequences = position_embedding_layer(Lambda(lambda x: K.arange(K.int_shape(x)[-1])+K.zeros_like(x,dtype='int32'))(newsinterval_input))\n",
    "\n",
    "news_encoders = add([news_encoders,action_embedded_sequences,dt_embedded_sequences,interval_embedded_sequences,position_embedded_sequences])\n",
    "u_att = Attention(16,16)([news_encoders,news_encoders,news_encoders])\n",
    "\n",
    "\n",
    "newsactionmask0 = Input((MAX_SENTS,), dtype='float32')\n",
    "newsactionmask1 = Input((MAX_SENTS,), dtype='float32')\n",
    "newsactionmask2 = Input((MAX_SENTS,), dtype='float32')\n",
    "newsactionmask3 = Input((MAX_SENTS,), dtype='float32')\n",
    "newsactionmask4 = Input((MAX_SENTS,), dtype='float32')\n",
    "newsactionmask5 = Input((MAX_SENTS,), dtype='float32') \n",
    "\n",
    "u_att0_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask0])\n",
    "u_att1_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask1])\n",
    "u_att2_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask2])\n",
    "u_att3_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask3])\n",
    "u_att4_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask4])\n",
    "u_att5_rep = Attention(16,16)([u_att,u_att,u_att,newsactionmask5])\n",
    "u_att3_att=Flatten()(Dense(1)(u_att3_rep))\n",
    "u_att4_att=Flatten()(Dense(1)(u_att4_rep))\n",
    "\n",
    "mask_pn=add([newsactionmask0,newsactionmask1])\n",
    "\n",
    "u_att_strong_exp_pos=Dot((1, 1))([u_att3_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att3_att,newsactionmask3]))]) \n",
    "u_att_strong_exp_neg=Dot((1, 1))([u_att4_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att4_att,newsactionmask4]))])\n",
    "\n",
    "u_att2_att=Dot((2, 1))([u_att2_rep,u_att_strong_exp_pos])\n",
    "u_att5_att=Dot((2, 1))([u_att5_rep,u_att_strong_exp_neg])\n",
    "u_att_strong_imp_pos=Dot((1, 1))([u_att2_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att2_att,newsactionmask2]))]) \n",
    "u_att_strong_imp_neg=Dot((1, 1))([u_att5_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att5_att,newsactionmask5]))])\n",
    "\n",
    "u_att_strong_pos=add([u_att_strong_exp_pos,u_att_strong_imp_pos])\n",
    "u_att_strong_neg=add([u_att_strong_exp_neg,u_att_strong_imp_neg])\n",
    "\n",
    "pn_rep = Lambda (lambda x:x[0]*K.expand_dims(x[2],axis=2)+x[1]*K.expand_dims(x[3],axis=2))([u_att0_rep,u_att1_rep,newsactionmask0,newsactionmask1])\n",
    "\n",
    "u_att0_att=Dot((2, 1))([pn_rep,u_att_strong_exp_pos])\n",
    "u_att1_att=Dot((2, 1))([pn_rep,u_att_strong_exp_neg])\n",
    "u_att_weak_imp_pos=Dot((1, 1))([pn_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att0_att,mask_pn]))]) \n",
    "u_att_weak_imp_neg=Dot((1, 1))([pn_rep,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*99)([u_att1_att,mask_pn]))])\n",
    "\n",
    "pndisentangle=Lambda(lambda x:K.abs(x))(Dot((1,1), normalize=True)([Lambda(lambda x:x+1e-8)(u_att_weak_imp_pos),Lambda(lambda x:x+1e-8)(u_att_weak_imp_neg)]))\n",
    "\n",
    "\n",
    "\n",
    "posvec =concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [u_att_strong_exp_pos,u_att_strong_imp_pos]],axis=1)\n",
    "attentionv= Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(posvec))))\n",
    "u_strong_pos=keras.layers.Dot((1, 1))([posvec, attentionv])\n",
    "\n",
    "negvec =concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [u_att_strong_exp_neg,u_att_strong_imp_neg]],axis=1)\n",
    "attentionv2= Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(negvec))))\n",
    "u_strong_neg=keras.layers.Dot((1, 1))([negvec, attentionv2])\n",
    "\n",
    "allvec =concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [u_strong_pos,u_strong_neg,u_att_weak_imp_pos,u_att_weak_imp_neg]],axis=1)\n",
    "attention_final= Activation('softmax')(Flatten()(Dense(1)(allvec)))\n",
    "uemb=keras.layers.Dot((1, 1))([allvec, attention_final])\n",
    "\n",
    "#u_att = Dot((1, 1))([news_encoders,Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(news_encoders ))))])\n",
    "\n",
    "candidates=Input((1+npratio,MAX_SENT_LENGTH,), dtype='int32')\n",
    "candidate_vecs=TimeDistributed(sentEncodert)(candidates)\n",
    "\n",
    "logits = Activation('softmax')(keras.layers.dot([candidate_vecs, uemb], axes=-1)) \n",
    "pred_dense1=Dense(256)(candidate_vecs)\n",
    "pred_dense2=Dense(256)(candidate_vecs)\n",
    "\n",
    "finish = Activation('softmax')(keras.layers.dot([pred_dense1, uemb], axes=-1))\n",
    "dwelltime = Lambda(lambda x:K.sum(x,axis=-1,keepdims=True))(Activation('relu')(keras.layers.dot([pred_dense2, uemb], axes=-1)))\n",
    "\n",
    "model = Model([candidates,news_input,newsaction_input,newsdt_input,newsinterval_input,newsactionmask0,newsactionmask1,\n",
    "               newsactionmask2,newsactionmask3,newsactionmask4,newsactionmask5], [logits,dwelltime,finish,pndisentangle])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy','mae','categorical_crossentropy','mae'], optimizer=Adam(lr=0.0001),metrics=['acc'],loss_weights=[1.,0.15,0.3,0.2])\n",
    "\n",
    "\n",
    "candidate_one = keras.Input((MAX_SENT_LENGTH,)) \n",
    "\n",
    "candidate_one_vec = sentEncodert([candidate_one]) \n",
    "\n",
    "score = keras.layers.dot([candidate_one_vec, uemb], axes=-1) \n",
    "\n",
    "model2 = keras.Model([candidate_one,news_input,newsaction_input,newsdt_input,newsinterval_input,newsactionmask0,newsactionmask1,\n",
    "               newsactionmask2,newsactionmask3,newsactionmask4,newsactionmask5], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.optimizers import *\n",
    "results=[]\n",
    "all_pred=[]\n",
    "for ep in range(1):\n",
    "    traingen=generate_batch_data_random(50)\n",
    "    model.fit_generator(traingen, epochs=1,steps_per_epoch=len(train_label)//50)\n",
    "    valgen=generate_batch_data(50)\n",
    "    ider=0\n",
    "    cr = model2.predict_generator(valgen, steps=len(test_label)//50,verbose=1)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    all_auc=[]\n",
    "    all_mrr=[]\n",
    "    all_ndcg=[]\n",
    "    all_ndcg2=[]\n",
    "    for m in test_index:\n",
    "        if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "    \n",
    "            all_auc.append(roc_auc_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0]))\n",
    "            all_mrr.append(mrr_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0]))\n",
    "            all_ndcg.append(ndcg_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0],k=5))\n",
    "            all_ndcg2.append(ndcg_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0],k=10))\n",
    "    print(np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2))\n",
    "    \n",
    "    allf=0\n",
    "    topf=0\n",
    "    topdt=0\n",
    "    alls=0\n",
    "    alld=0\n",
    "    \n",
    "    clicks=0\n",
    "    alldtr=0\n",
    "    alldtc=0\n",
    "    for m in test_index:\n",
    "        if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "            dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "            clicks+=np.sum(test_label[m[0]:m[1]][dd])\n",
    "            topdt+=np.mean(test_candidate_dt[m[0]:m[1]][dd])\n",
    "            for j in test_candidate_action[m[0]:m[1]]:\n",
    "                if j==3:\n",
    "                    allf+=1\n",
    "                \n",
    "            for j in dd:\n",
    "                if test_candidate_action[m[0]:m[1]][j]==3:\n",
    "                    topf+=1\n",
    "                    \n",
    "                if test_candidate_action[m[0]:m[1]][j]==4:\n",
    "                    alls+=1\n",
    "                if test_candidate_action[m[0]:m[1]][j]==5:\n",
    "                    alld+=1\n",
    "                    \n",
    "                if test_candidate_action[m[0]:m[1]][j]==2:\n",
    "                    alldtc+=1\n",
    "                    alldtr+=test_candidate_dt[m[0]:m[1]][j]\n",
    "                    \n",
    "    print(allf,topf,topdt/len(test_index),alls/len(test_index)/5,alld/len(test_index)/5)\n",
    "    results.append([np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2),clicks/5/len(test_index),alldtr/alldtc,alls/len(test_index)/5,alld/len(test_index)/5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks=0\n",
    "for m in test_index:\n",
    "    if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "        dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "        #print(dd)\n",
    "        clicks+=np.sum(test_label[m[0]:m[1]][dd])\n",
    "print(clicks/5/len(test_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.00012239-9.704349e-5)/9.704349e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0003168659698026204+0.0002825636925176165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0005396/0.0005994296623202369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf=0\n",
    "topf=0\n",
    "topdt=0\n",
    "alls=0\n",
    "alld=0\n",
    "for m in test_index:\n",
    "    if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "        dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "        #print(dd)\n",
    "        topdt+=np.mean(test_candidate_dt[m[0]:m[1]][dd])\n",
    "        for j in test_candidate_action[m[0]:m[1]]:\n",
    "            if j==3:\n",
    "                allf+=1\n",
    "            \n",
    "        for j in dd:\n",
    "            if test_candidate_action[m[0]:m[1]][j]==3:\n",
    "                topf+=1\n",
    "                \n",
    "            if test_candidate_action[m[0]:m[1]][j]==4:\n",
    "                alls+=1\n",
    "            if test_candidate_action[m[0]:m[1]][j]==5:\n",
    "                alld+=1\n",
    "print(allf,topf,topdt/len(test_index),alls/len(test_index)/5,alld/len(test_index)/5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf=0\n",
    "topf=0\n",
    "topdt=0\n",
    "alls=0\n",
    "alld=0\n",
    "for m in test_index:\n",
    "    if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "        dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "        #print(dd)\n",
    "        topdt+=np.mean(test_candidate_dt[m[0]:m[1]][dd])\n",
    "        for j in test_candidate_action[m[0]:m[1]]:\n",
    "            if j==3:\n",
    "                allf+=1\n",
    "            \n",
    "        for j in dd:\n",
    "            if test_candidate_action[m[0]:m[1]][j]==3:\n",
    "                topf+=1\n",
    "                \n",
    "            if test_candidate_action[m[0]:m[1]][j]==4:\n",
    "                alls+=1\n",
    "            if test_candidate_action[m[0]:m[1]][j]==5:\n",
    "                alld+=1\n",
    "print(allf,topf,topdt/len(test_index),alls/len(test_index)/5,alld/len(test_index)/5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf=0\n",
    "topf=0\n",
    "topdt=0\n",
    "alls=0\n",
    "alld=0\n",
    "for m in test_index:\n",
    "    if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "        dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "        #print(dd)\n",
    "        topdt+=np.mean(test_candidate_dt[m[0]:m[1]][dd])\n",
    "        for j in test_candidate_action[m[0]:m[1]]:\n",
    "            if j==3:\n",
    "                allf+=1\n",
    "            \n",
    "        for j in dd:\n",
    "            if test_candidate_action[m[0]:m[1]][j]==3:\n",
    "                topf+=1\n",
    "                \n",
    "            if test_candidate_action[m[0]:m[1]][j]==4:\n",
    "                alls+=1\n",
    "            if test_candidate_action[m[0]:m[1]][j]==5:\n",
    "                alld+=1\n",
    "print(allf,topf,topdt/len(test_index),alls/len(test_index)/5,alld/len(test_index)/5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share 9.704349479606015e-05\n",
    "0.0003168659698026204+0.0002825636925176165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allf=0\n",
    "topf=0\n",
    "topdt=0\n",
    "for m in test_index:\n",
    "    if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "        dd=np.argsort(cr[m[0]:m[1],0])[::-1][:5]\n",
    "        #print(dd)\n",
    "        topdt+=np.mean(test_candidate_dt[m[0]:m[1]][dd])\n",
    "        for j in test_candidate_action[m[0]:m[1]]:\n",
    "            if j==3:\n",
    "                allf+=1\n",
    "        for j in dd:\n",
    "            if test_candidate_action[m[0]:m[1]][j]==3:\n",
    "                topf+=1\n",
    "print(allf,topf,topdt/len(test_index))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH=30\n",
    "MAX_SENTS=200\n",
    "\n",
    "loss_action_weight={0:1.,1:1.,2:1.,3:2.,4:3.,5:3.,6:1.,-1:0.}\n",
    "def generate_batch_data_random(batch_size):\n",
    "    idlist = np.arange(len(train_label))\n",
    "    np.random.shuffle(idlist)\n",
    "    y=train_label\n",
    "    batches = [idlist[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[train_candidate[i]]\n",
    "            user = news_title[train_user_his[i]] \n",
    "            useraction = train_user_hisaction[i]\n",
    "            itemaction= train_candidate_action[i]\n",
    "            useractionmask0=train_user_hismask0[i]\n",
    "            useractionmask1=train_user_hismask1[i]\n",
    "            useractionmask2=train_user_hismask2[i]\n",
    "            useractionmask3=train_user_hismask3[i]\n",
    "            useractionmask4=train_user_hismask4[i]\n",
    "            useractionmask5=train_user_hismask5[i]\n",
    "            useractionmask6=train_user_hismask6[i]\n",
    "            itemdt=train_candidate_dt[i]\n",
    "            yield ([item,user,useraction,useractionmask0,useractionmask1,\n",
    "                    useractionmask2,useractionmask3,useractionmask4,useractionmask5,useractionmask6], [y[i]])#,itemdt,to_categorical(itemaction,4)\n",
    "            \n",
    "\n",
    "\n",
    "def generate_batch_data(batch_size):\n",
    "    idlist = np.arange(len(test_candidate))\n",
    "    batches = [idlist[range(batch_size*i, min(len(idlist), batch_size*(i+1)))] for i in range(len(idlist)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[test_candidate[i]]\n",
    "            user=news_title[test_user_his[i]]\n",
    "            useraction = test_user_hisaction[i]\n",
    "            useractionmask0=test_user_hismask0[i]\n",
    "            useractionmask1=test_user_hismask1[i]\n",
    "            useractionmask2=test_user_hismask2[i]\n",
    "            useractionmask3=test_user_hismask3[i]\n",
    "            useractionmask4=test_user_hismask4[i]\n",
    "            useractionmask5=test_user_hismask5[i]\n",
    "            useractionmask6=test_user_hismask6[i]\n",
    "            yield ([item,user,useraction,useractionmask0,useractionmask1,useractionmask2,useractionmask3,useractionmask4,useractionmask5,useractionmask6])\n",
    "            \n",
    "\n",
    "\n",
    "keras.backend.clear_session() \n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(word_dict1), 300, weights=[lister],trainable=True)\n",
    " \n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "\n",
    "d_et=Dropout(0.2)(embedded_sequences)\n",
    "\n",
    "\n",
    "d_ct= Attention(16,16)([d_et,d_et,d_et])\n",
    "#l_att=Dense(64,activation='tanh')(l_att)\n",
    "attention = Dense(200,activation='tanh')(d_ct)\n",
    "attention = Flatten()(Dense(1)(attention))\n",
    "attention_weight = Activation('softmax')(attention)\n",
    "l_att=keras.layers.Dot((1, 1))([d_ct, attention_weight])\n",
    "\n",
    "\n",
    "sentEncodert = Model([sentence_input], l_att)\n",
    "\n",
    "\n",
    "review_input = Input((MAX_SENTS,MAX_SENT_LENGTH,), dtype='int32')\n",
    "review_encoders= TimeDistributed(sentEncodert)(review_input)\n",
    "\n",
    "reviewaction_input = Input((MAX_SENTS,), dtype='int32')\n",
    "actionembedding_layer = Embedding(7, 256,trainable=True)\n",
    " \n",
    "action_embedded_sequences = actionembedding_layer(reviewaction_input)\n",
    "\n",
    "review_encoders = add([review_encoders,action_embedded_sequences])\n",
    "u_att = Attention(16,16)([review_encoders,review_encoders,review_encoders])\n",
    "\n",
    "\n",
    "reviewactionmask0 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask1 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask2 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask3 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask4 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask5 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask6 = Input((MAX_SENTS,), dtype='float32')\n",
    "\n",
    "\n",
    "u_att012raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders ))) \n",
    "\n",
    "u_att012rawn=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders ))) \n",
    "\n",
    "u_att3raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders )))\n",
    "u_att4raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders )))\n",
    "u_att5raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders )))\n",
    "u_att6raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders )))\n",
    "\n",
    "mask012=add([reviewactionmask0,reviewactionmask1,reviewactionmask2])\n",
    "\n",
    "u_att012=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att012raw,mask012]))]) \n",
    "\n",
    "u_att012n=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att012rawn,mask012]))])\n",
    "\n",
    "\n",
    "u_att3=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att3raw,reviewactionmask3]))])\n",
    "u_att4=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att4raw,reviewactionmask4]))])\n",
    "u_att5=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att5raw,reviewactionmask5]))])\n",
    "u_att6=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att6raw,reviewactionmask6]))])\n",
    "\n",
    "u_att_strong_exp_pos=Dense(256)(u_att4)\n",
    "u_att_strong_imp_pos=Dense(256)(u_att3)\n",
    "\n",
    "posvec =concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [u_att_strong_exp_pos,u_att_strong_imp_pos]],axis=1)\n",
    "attentionv= Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(posvec))))\n",
    "u_att_strong_pos=keras.layers.Dot((1, 1))([posvec, attentionv])\n",
    "\n",
    "negvec =concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [u_att5,u_att6]],axis=1)\n",
    "attentionv2= Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(negvec))))\n",
    "u_att_strong_neg=keras.layers.Dot((1, 1))([negvec, attentionv2])\n",
    "\n",
    "\n",
    "u_att_weak_imp_pos=Dense(256)(u_att012)\n",
    "u_att_weak_imp_neg=Dense(256)(u_att012n)\n",
    "\n",
    "\n",
    "#u_att = Dot((1, 1))([review_encoders,Activation('softmax')(Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders ))))])\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    " \n",
    "loss1=Lambda(cosine_distance)([u_att_weak_imp_pos,u_att_weak_imp_neg])\n",
    "loss2=Lambda(cosine_distance)([u_att_weak_imp_pos,u_att_strong_pos])\n",
    "loss3=Lambda(cosine_distance)([u_att_weak_imp_neg,u_att_strong_neg])\n",
    "\n",
    "def myloss(y_true, y_pred):\n",
    "    return K.mean(K.abs(loss1))-K.mean(K.abs(loss2))-K.mean(K.abs(loss3))\n",
    "\n",
    "candidates=Input((1+npratio,MAX_SENT_LENGTH,), dtype='int32')\n",
    "candidate_vecs=TimeDistributed(sentEncodert)(candidates)\n",
    "\n",
    "logits1 = keras.layers.dot([candidate_vecs, u_att_strong_pos], axes=-1)\n",
    "logits2 = keras.layers.dot([candidate_vecs, u_att_weak_imp_pos], axes=-1)\n",
    "logits3 = keras.layers.dot([candidate_vecs, u_att_weak_imp_neg], axes=-1)\n",
    "logits4 = keras.layers.dot([candidate_vecs, u_att_strong_neg], axes=-1)\n",
    "\n",
    "labeldense=Dense(1)\n",
    "\n",
    "#pred1dense1=Dense(256)\n",
    "#pred1dense2=Dense(256)\n",
    "\n",
    "\n",
    "\n",
    "#logits1 = keras.layers.dot([candidate_vecs, u_att_strong_pos], axes=-1)\n",
    "#logits2 = keras.layers.dot([candidate_vecs, u_att_weak_imp_pos], axes=-1)\n",
    "#logits3 = keras.layers.dot([candidate_vecs, u_att_weak_imp_neg], axes=-1)\n",
    "#logits4 = keras.layers.dot([candidate_vecs, u_att_strong_neg], axes=-1)\n",
    "#\n",
    "logitscon = concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(vec) for vec in [logits1,logits2,logits3,logits4]],axis=1)\n",
    "\n",
    "logitscon = Activation('softmax')(Flatten()(TimeDistributed(labeldense)(Lambda (lambda x:K.permute_dimensions(x, (0,2,1)))(logitscon))))\n",
    "candidates_action=Input((1+npratio,), dtype='float32')\n",
    "\n",
    "model = Model([candidates,review_input,reviewaction_input,reviewactionmask0,reviewactionmask1,\n",
    "               reviewactionmask2,reviewactionmask3,reviewactionmask4,reviewactionmask5,reviewactionmask6], [logitscon])\n",
    "\n",
    "def myloss2(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true-y_pred)*candidates_action)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy'], optimizer=Adam(lr=0.0001),metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "candidate_one = keras.Input((MAX_SENT_LENGTH,)) \n",
    "\n",
    "candidate_one_vec = sentEncodert([candidate_one]) \n",
    "#newsEncodert = Model([candidate_one], candidate_one_vec)\n",
    "\n",
    "score1 = keras.layers.dot([candidate_one_vec, u_att_strong_pos], axes=-1)\n",
    "score2 = keras.layers.dot([candidate_one_vec, u_att_weak_imp_pos], axes=-1)\n",
    "score3 = keras.layers.dot([candidate_one_vec, u_att_weak_imp_neg], axes=-1)\n",
    "score4 = keras.layers.dot([candidate_one_vec, u_att_strong_neg], axes=-1)\n",
    "\n",
    "scorecon = concatenate([score1,score2,score3,score4])\n",
    "\n",
    "logitscon = Activation('sigmoid')(labeldense(scorecon))\n",
    "\n",
    "#score = keras.layers.Activation(keras.activations.sigmoid)(keras.layers.dot([u_att, candidate_one_vec], axes=-1))\n",
    "model2 = keras.Model([candidate_one,review_input,reviewaction_input,reviewactionmask0,reviewactionmask1,\n",
    "               reviewactionmask2,reviewactionmask3,reviewactionmask4,reviewactionmask5,reviewactionmask6], logitscon)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH=30\n",
    "MAX_SENTS=200\n",
    "loss_action_weight={0:1.,1:1.,2:1.,3:2.,4:3.,5:3.,6:1.,-1:0.}\n",
    "def generate_batch_data_random(batch_size):\n",
    "    idlist = np.arange(len(train_label))\n",
    "    np.random.shuffle(idlist)\n",
    "    y=train_label\n",
    "    batches = [idlist[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[train_candidate[i]]\n",
    "            user = news_title[train_user_his[i]] \n",
    "            useraction = train_user_hisaction[i]\n",
    "            itemaction=np.array([[loss_action_weight[m] for m in t] for t in train_candidate_action[i]])\n",
    "            useractionmask2=train_user_hismask2[i]\n",
    "\n",
    "            yield ([item,user,useraction,itemaction,useractionmask2], [y[i]])\n",
    "            \n",
    "\n",
    "\n",
    "def generate_batch_data(batch_size):\n",
    "    idlist = np.arange(len(test_candidate))\n",
    "    batches = [idlist[range(batch_size*i, min(len(idlist), batch_size*(i+1)))] for i in range(len(idlist)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            item = news_title[test_candidate[i]]\n",
    "            user=news_title[test_user_his[i]]\n",
    "            useraction = test_user_hisaction[i]\n",
    "            useractionmask2=test_user_hismask2[i]\n",
    "            yield ([item,user,useraction,useractionmask2])\n",
    "            \n",
    "            \n",
    "keras.backend.clear_session() \n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(word_dict1), 300, weights=[lister],trainable=True)\n",
    " \n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "\n",
    "d_et=Dropout(0.2)(embedded_sequences)\n",
    "\n",
    "\n",
    "d_ct= Attention(16,16)([d_et,d_et,d_et])\n",
    "#l_att=Dense(64,activation='tanh')(l_att)\n",
    "attention = Dense(200,activation='tanh')(d_ct)\n",
    "attention = Flatten()(Dense(1)(attention))\n",
    "attention_weight = Activation('softmax')(attention)\n",
    "l_att=keras.layers.Dot((1, 1))([d_ct, attention_weight])\n",
    "\n",
    "\n",
    "sentEncodert = Model([sentence_input], l_att)\n",
    "\n",
    "\n",
    "review_input = Input((MAX_SENTS,MAX_SENT_LENGTH,), dtype='int32')\n",
    "review_encoders= TimeDistributed(sentEncodert)(review_input)\n",
    "\n",
    "reviewaction_input = Input((MAX_SENTS,), dtype='int32')\n",
    "actionembedding_layer = Embedding(7, 256,trainable=True)\n",
    " \n",
    "action_embedded_sequences = actionembedding_layer(reviewaction_input)\n",
    "\n",
    "u_att = add([review_encoders,action_embedded_sequences])\n",
    "#u_att = Attention(16,16)([review_encoders,review_encoders,review_encoders])\n",
    "\n",
    "\n",
    "reviewactionmask0 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask1 = Input((MAX_SENTS,), dtype='float32')\n",
    "reviewactionmask2 = Input((MAX_SENTS,), dtype='float32')\n",
    "\n",
    "u_att012raw=Flatten()(Dense(1)(Dense(200,activation='tanh')(review_encoders ))) \n",
    " \n",
    "mask012=reviewactionmask2#add([reviewactionmask0,reviewactionmask1,reviewactionmask2])\n",
    "\n",
    "u_att012=Dot((1, 1))([review_encoders,Activation('softmax')(Lambda (lambda x:x[0]-(1-x[1])*50)([u_att012raw,mask012]))]) \n",
    "\n",
    "candidates=Input((1+npratio,MAX_SENT_LENGTH,), dtype='int32')\n",
    "candidate_vecs=TimeDistributed(sentEncodert)(candidates)\n",
    "\n",
    "logits1 = keras.layers.dot([candidate_vecs, u_att012], axes=-1) \n",
    " \n",
    "logitscon = Activation('softmax')(logits1)\n",
    "candidates_action=Input((1+npratio,), dtype='float32')\n",
    "\n",
    "model = Model([candidates,review_input,reviewaction_input,candidates_action,\n",
    "               reviewactionmask2], [logitscon])\n",
    "\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy'], optimizer=Adam(lr=0.0001),metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "candidate_one = keras.Input((MAX_SENT_LENGTH,)) \n",
    "\n",
    "candidate_one_vec = sentEncodert([candidate_one]) \n",
    "#newsEncodert = Model([candidate_one], candidate_one_vec)\n",
    "\n",
    "score1 = keras.layers.dot([candidate_one_vec, u_att012], axes=-1)\n",
    "#score2 = keras.layers.dot([candidate_one_vec, u_att_weak_imp_pos], axes=-1)\n",
    "#score3 = keras.layers.dot([candidate_one_vec, u_att_weak_imp_neg], axes=-1)\n",
    "#score4 = keras.layers.dot([candidate_one_vec, u_att_strong_neg], axes=-1)\n",
    "#\n",
    "scorecon = score1#concatenate([score1,score2,score3,score4])\n",
    "\n",
    "logitscon = Activation('sigmoid')(scorecon)\n",
    "\n",
    "#score = keras.layers.Activation(keras.activations.sigmoid)(keras.layers.dot([u_att, candidate_one_vec], axes=-1))\n",
    "model2 = keras.Model([candidate_one,review_input,reviewaction_input,\n",
    "               reviewactionmask2], logitscon)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_auc(label,score):\n",
    "    label=np.array(label)\n",
    "    score=np.array(score)\n",
    "    false_score = score[label==0]\n",
    "    positive_score = score[label==1]\n",
    "    num_positive = (label==1).sum()\n",
    "    num_negative = (label==0).sum()\n",
    "    positive_score = positive_score.reshape((num_positive,1))\n",
    "    positive_score = np.repeat(positive_score,num_negative,axis=1)\n",
    "    false_score = false_score.reshape((1,num_negative))\n",
    "    false_score = np.repeat(false_score,num_positive,axis=0)\n",
    "    return 1-((positive_score<false_score).mean()+0.5*(positive_score==false_score).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import *\n",
    "results=[]\n",
    "all_pred=[]\n",
    "for ep in range(5):\n",
    "    traingen=generate_batch_data_random(50)\n",
    "    model.fit_generator(traingen, epochs=1,steps_per_epoch=len(train_label)//50)\n",
    "    valgen=generate_batch_data(50)\n",
    "    ider=0\n",
    "    cr = model2.predict_generator(valgen, steps=len(test_label)//50,verbose=1)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    all_auc=[]\n",
    "    all_mrr=[]\n",
    "    all_ndcg=[]\n",
    "    all_ndcg2=[]\n",
    "    for m in test_index:\n",
    "        if np.sum(test_label[m[0]:m[1]])!=0 and m[1]<len(cr):\n",
    "    \n",
    "            all_auc.append(roc_auc_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0]))\n",
    "            all_mrr.append(mrr_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0]))\n",
    "            all_ndcg.append(ndcg_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0],k=5))\n",
    "            all_ndcg2.append(ndcg_score(test_label[m[0]:m[1]],cr[m[0]:m[1],0],k=10))\n",
    "    results.append([np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2)])\n",
    "    print(np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
